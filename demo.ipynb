{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéôÔ∏è ASR Project Demo (CTC-BiLSTM)\n",
        "\n",
        "–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. üõ†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∫–æ–¥–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "USER = 'Olga57'\n",
        "REPO = 'speech-recognition-ctc'\n",
        "\n",
        "if not os.path.exists(REPO):\n",
        "    !git clone https://github.com/{USER}/{REPO}.git\n",
        "\n",
        "%cd {REPO}\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q gdown hydra-core omegaconf\n",
        "!apt-get install -y libsndfile1 ffmpeg > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç (Librispeech)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—É—Ç–∏ (—á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å src)\n",
        "project_root = os.getcwd()\n",
        "os.environ['PYTHONPATH'] = project_root\n",
        "\n",
        "# 2. –ó–ê–ü–£–°–ö (–° –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º train_source=null)\n",
        "# –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º +, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–æ–Ω—Ñ–∏–≥–µ\n",
        "!python inference.py dataset=librispeech \\\n",
        "    +dataset.valid_split=validation.clean \\\n",
        "    +dataset.max_valid_items=5 \\\n",
        "    +dataset.train_source=null \\\n",
        "    +device='cuda' \\\n",
        "    +decode='beam' \\\n",
        "    +out_dir='predictions_libri'\n",
        "\n",
        "!head -n 5 predictions_libri/*.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. üìÇ –¢–µ—Å—Ç –Ω–∞ –≤–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (Google Drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "import os\n",
        "os.environ['PYTHONPATH'] = os.getcwd()\n",
        "url = input('–°—Å—ã–ª–∫–∞ –Ω–∞ Google Drive (ZIP): ')\n",
        "if 'drive.google.com' in url:\n",
        "    file_id = url.split('/d/')[-1].split('/')[0]\n",
        "    dl_url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    gdown.download(dl_url, 'custom.zip', quiet=False)\n",
        "    !unzip -q -o custom.zip -d custom_data\n",
        "    ds_root = 'custom_data'\n",
        "    for r, d, f in os.walk('custom_data'):\n",
        "        if 'audio' in d: ds_root = r\n",
        "    # –¢—É—Ç —Ç–æ–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º train_source=null\n",
        "    !python inference.py dataset=custom dataset.custom_root=\"{ds_root}\" \\\n",
        "         +device='cuda' +decode='beam' +out_dir='preds_custom' +dataset.train_source=null\n",
        "    !python calc_metrics.py --ref_dir \"{ds_root}/transcriptions\" --hyp_dir \"preds_custom\"\n",
        "else:\n",
        "    print('–≠—Ç–æ –Ω–µ —Å—Å—ã–ª–∫–∞ –Ω–∞ Google Drive')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}